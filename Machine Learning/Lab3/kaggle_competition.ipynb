{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "standardize = StandardScaler()\n",
    "\n",
    "df_train = pd.read_csv('train.csv',sep =\";\")\n",
    "df_test = pd.read_csv('testReal.csv', sep =\",\", index_col = False,  header = None, names = [\"age\", \"job\", \"marital\", \"education\",\"default\",\"housing\",\"loan\",\"contact\",\"month\",\"day_of_week\",\"duration\",\"campaign\",\"pdays\",\"previous\",\"poutcome\",\"emp.var.rate\",\"cons.price.idx\",\"cons.conf.idx\",\"euribor3m\",\"nr.employed\",\"y\"])\n",
    "\n",
    "#df_test = pd.read_csv('test.csv', sep =\";\", index_col = False,  header = None, names = [\"age\", \"job\", \"marital\", \"education\",\"default\",\"housing\",\"loan\",\"contact\",\"month\",\"day_of_week\",\"duration\",\"campaign\",\"pdays\",\"previous\",\"poutcome\",\"emp.var.rate\",\"cons.price.idx\",\"cons.conf.idx\",\"euribor3m\",\"nr.employed\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------\n"
     ]
    }
   ],
   "source": [
    "#print(df_train.head(5))\n",
    "print(\"-------------\")\n",
    "#print(df_train.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------\n"
     ]
    }
   ],
   "source": [
    "#print(df_test.head(5))\n",
    "print(\"-------------\")\n",
    "#print(df_test.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "full_data = [df_train,df_test] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# What is the proportion of 1's to 0's in the output?\n",
    "# Get last column, since it is a column with a string header, we need to use iloc\n",
    "#y = df_train.iloc[:,-1]\n",
    "#counts = y.value_counts()\n",
    "#print(counts)\n",
    "# So the proportion is almost 1 to 8.\n",
    "# This could mean that we need to do sampling or use some classifying algorithms doing good against overfitting\n",
    "\n",
    "# or maybe use naive bayes approach to deal with missing data, but we need to check variances\n",
    "# for not re-evaluating strong parametres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# preprocessing part, fill some unknown values, maybe remove some columns, create some categories\n",
    "# normalize some columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'job = df_train.iloc[:,1]\\ncounts = job.value_counts()\\nprint(counts)\\njob = df_test.iloc[:,1]\\ncounts = job.value_counts()\\nprint(counts)'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"job = df_train.iloc[:,1]\n",
    "counts = job.value_counts()\n",
    "print(counts)\n",
    "job = df_test.iloc[:,1]\n",
    "counts = job.value_counts()\n",
    "print(counts)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'marital = df_train.iloc[:,2]\\ncounts = marital.value_counts()\\nprint(counts)\\n# could be filled with married\\nmarital = df_test.iloc[:,2]\\ncounts = marital.value_counts()\\nprint(counts)'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"marital = df_train.iloc[:,2]\n",
    "counts = marital.value_counts()\n",
    "print(counts)\n",
    "# could be filled with married\n",
    "marital = df_test.iloc[:,2]\n",
    "counts = marital.value_counts()\n",
    "print(counts)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'education = df_train.iloc[:,3]\\ncounts = education.value_counts()\\nprint(counts)\\neducation = df_test.iloc[:,3]\\ncounts = education.value_counts()\\nprint(counts)'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"education = df_train.iloc[:,3]\n",
    "counts = education.value_counts()\n",
    "print(counts)\n",
    "education = df_test.iloc[:,3]\n",
    "counts = education.value_counts()\n",
    "print(counts)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'default = df_train.iloc[:,4]\\ncounts = default.value_counts()\\nprint(counts)\\ndefault = df_test.iloc[:,4]\\ncounts = default.value_counts()\\nprint(counts)'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"default = df_train.iloc[:,4]\n",
    "counts = default.value_counts()\n",
    "print(counts)\n",
    "default = df_test.iloc[:,4]\n",
    "counts = default.value_counts()\n",
    "print(counts)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'housing = df_train.iloc[:,5]\\ncounts = housing.value_counts()\\nprint(counts)\\nhousing = df_test.iloc[:,5]\\ncounts = housing.value_counts()\\nprint(counts)'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"housing = df_train.iloc[:,5]\n",
    "counts = housing.value_counts()\n",
    "print(counts)\n",
    "housing = df_test.iloc[:,5]\n",
    "counts = housing.value_counts()\n",
    "print(counts)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'loan = df_train.iloc[:,6]\\ncounts = loan.value_counts()\\nprint(counts)\\nloan = df_test.iloc[:,6]\\ncounts = loan.value_counts()\\nprint(counts)'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"loan = df_train.iloc[:,6]\n",
    "counts = loan.value_counts()\n",
    "print(counts)\n",
    "loan = df_test.iloc[:,6]\n",
    "counts = loan.value_counts()\n",
    "print(counts)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'contact = df_train.iloc[:,7]\\ncounts = contact.value_counts()\\nprint(counts)\\ncontact = df_test.iloc[:,7]\\ncounts = contact.value_counts()\\nprint(counts)'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"contact = df_train.iloc[:,7]\n",
    "counts = contact.value_counts()\n",
    "print(counts)\n",
    "contact = df_test.iloc[:,7]\n",
    "counts = contact.value_counts()\n",
    "print(counts)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'month = df_train.iloc[:,8]\\ncounts = month.value_counts()\\nprint(counts)\\nmonth = df_test.iloc[:,8]\\ncounts = month.value_counts()\\nprint(counts)'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"month = df_train.iloc[:,8]\n",
    "counts = month.value_counts()\n",
    "print(counts)\n",
    "month = df_test.iloc[:,8]\n",
    "counts = month.value_counts()\n",
    "print(counts)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dof = df_train.iloc[:,9]\\ncounts = dof.value_counts()\\nprint(counts)\\ndof = df_test.iloc[:,9]\\ncounts = dof.value_counts()\\nprint(counts)'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"dof = df_train.iloc[:,9]\n",
    "counts = dof.value_counts()\n",
    "print(counts)\n",
    "dof = df_test.iloc[:,9]\n",
    "counts = dof.value_counts()\n",
    "print(counts)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'duration = df_train.iloc[:,10]\\nprint(duration.describe())\\nduration = df_test.iloc[:,10]\\nprint(duration.describe())'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"duration = df_train.iloc[:,10]\n",
    "print(duration.describe())\n",
    "duration = df_test.iloc[:,10]\n",
    "print(duration.describe())\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'campaign = df_train.iloc[:,11]\\ncounts = campaign.value_counts()\\nprint(counts)\\ncampaign = df_test.iloc[:,11]\\ncounts = campaign.value_counts()\\nprint(counts)'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"campaign = df_train.iloc[:,11]\n",
    "counts = campaign.value_counts()\n",
    "print(counts)\n",
    "campaign = df_test.iloc[:,11]\n",
    "counts = campaign.value_counts()\n",
    "print(counts)\"\"\"\n",
    "# to many categories we low cardinality, if we want to use naive bayes approach we want to change some values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pdays = df_train.iloc[:,12]\\nprint(pdays.describe())\\ncounts = pdays.value_counts()\\nprint(counts)\\npdays = df_test.iloc[:,12]\\nprint(pdays.describe())\\ncounts = pdays.value_counts()\\nprint(counts)'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"pdays = df_train.iloc[:,12]\n",
    "print(pdays.describe())\n",
    "counts = pdays.value_counts()\n",
    "print(counts)\n",
    "pdays = df_test.iloc[:,12]\n",
    "print(pdays.describe())\n",
    "counts = pdays.value_counts()\n",
    "print(counts)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'previous = df_train.iloc[:,13]\\ncounts = previous.value_counts()\\nprint(counts)\\nprevious = df_test.iloc[:,13]\\ncounts = previous.value_counts()\\nprint(counts)'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"previous = df_train.iloc[:,13]\n",
    "counts = previous.value_counts()\n",
    "print(counts)\n",
    "previous = df_test.iloc[:,13]\n",
    "counts = previous.value_counts()\n",
    "print(counts)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#poutcome = df_train.iloc[:,14]\n",
    "#counts = poutcome.value_counts()\n",
    "#print(counts)\n",
    "# to many unknown valeus maybe pass this one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for dataset in full_data:\n",
    "    # Map aging\n",
    "    #dataset.loc[(dataset['age'] >= 18) & (dataset['age'] <= 32), 'age'] = 0\n",
    "    #dataset.loc[(dataset['age'] > 32) & (dataset['age'] <= 38), 'age'] = 1\n",
    "    #dataset.loc[(dataset['age'] > 38) & (dataset['age'] <= 47), 'age'] = 2\n",
    "    #dataset.loc[ dataset['age'] > 47, 'age'] = 4 ;\n",
    "\n",
    "    #map marital\n",
    "    dataset.loc[ dataset['marital'] == 'unknown', 'marital'] = 'married' ;\n",
    "    #dataset.loc[ dataset['marital'] == 'married', 'marital'] = '0' ;\n",
    "    #dataset.loc[ dataset['marital'] == 'single', 'marital'] = '1' ;\n",
    "    #dataset.loc[ dataset['marital'] == 'divorced', 'marital'] = '2' ;    \n",
    "    \n",
    "    #map job\n",
    "    #dataset.loc[(dataset['job'] == 'unknown') & ((dataset['education'] == 'basic.4y') or (dataset['education'] == 'basic.6y') ), 'job'] = 0\n",
    "    #dataset.loc[(dataset['job'] == \"unknown\") & (dataset['age'] == 0), 'job'] = 'student'\n",
    "    #dataset.loc[(dataset['job'] == \"unknown\"), 'job'] = 'admin.'\n",
    "    \n",
    "    #map education\n",
    "    dataset.loc[(dataset['education'] == \"unknown\"), 'education'] = 'basic.9y'\n",
    "    dataset.loc[ dataset['education'] == 'basic.6y', 'education'] = 'low' ;\n",
    "    dataset.loc[ dataset['education'] == 'basic.4y', 'education'] = 'low' ;\n",
    "    dataset.loc[ dataset['education'] == 'professional.course', 'education'] = 'medium' ;\n",
    "    dataset.loc[ dataset['education'] == 'basic.9y', 'education'] = 'medium' ;\n",
    "    dataset.loc[ dataset['education'] == 'high.school', 'education'] = 'medium'    \n",
    "    dataset.loc[ dataset['education'] == 'university.degree', 'education'] = 'high' ;\n",
    "    dataset.loc[ dataset['education'] == 'illiterate', 'education'] = 'low' ;\n",
    "        \n",
    "    #map housing\n",
    "    dataset.loc[(dataset['housing'] == \"unknown\"), 'housing'] = 'yes'\n",
    "    dataset.loc[(dataset['housing'] == \"yes\"), 'housing'] = 'housingYes'\n",
    "    dataset.loc[(dataset['housing'] == \"no\"), 'housing'] = 'housingNo'\n",
    "    \n",
    "    #map loan\n",
    "    dataset.loc[(dataset['loan'] == \"unknown\"), 'loan'] = 'no'\n",
    "    dataset.loc[(dataset['loan'] == \"yes\"), 'loan'] = 'loanYes'\n",
    "    dataset.loc[(dataset['loan'] == \"no\"), 'loan'] = 'loanNo'\n",
    "    \n",
    "    #map contact\n",
    "    #map month \n",
    "    #map day_of_week\n",
    "\n",
    "    # map duration\n",
    "    #dataset.loc[(dataset['duration'] >= 0) & (dataset['duration'] <= 101), 'duration'] = 0\n",
    "    #dataset.loc[(dataset['duration'] > 101) & (dataset['duration'] <= 180), 'duration'] = 1\n",
    "    #dataset.loc[(dataset['duration'] > 180) & (dataset['duration'] <= 316), 'duration'] = 2\n",
    "    #dataset.loc[ dataset['duration'] > 316, 'duration'] = 3 ;\n",
    "    \n",
    "    #map campaign\n",
    "    # map pdays\n",
    "    dataset.loc[(dataset['pdays'] >= 0) & (dataset['pdays'] < 999), 'pdays'] = \"pone\" \n",
    "    dataset.loc[ dataset['pdays'] == 999, 'pdays'] = \"ptwo\" ;\n",
    "    \n",
    "    # map previous\n",
    "    dataset.loc[dataset['previous'] > 0 , 'previous'] = \"previousone\" \n",
    "    dataset.loc[dataset['previous'] == 0 , 'previous'] = \"previouszero\" \n",
    "\n",
    "    # map poutcome\n",
    "    dataset.loc[(dataset['poutcome'] == \"nonexistent\"), 'poutcome'] = 'failure'\n",
    "    dataset.loc[(dataset['poutcome'] == \"success\"), 'poutcome'] = 'poutuccess'\n",
    "    dataset.loc[(dataset['poutcome'] == \"failure\"), 'poutcome'] = 'poutfail'\n",
    "\n",
    "# turn y column to 0's and 1's\n",
    "df_train.loc[ df_train['y'] == 'no', 'y'] = 0 \n",
    "df_train.loc[ df_train['y'] == 'yes', 'y'] = 1 \n",
    "df_test.loc[ df_test['y'] == 'no', 'y'] = 0 \n",
    "df_test.loc[ df_test['y'] == 'yes', 'y'] = 1 \n",
    "\n",
    "df_sex = pd.get_dummies(df_test['education'])\n",
    "df_test = pd.concat([df_test, df_sex], axis=1)\n",
    "\n",
    "df_sex = pd.get_dummies(df_train['education'])\n",
    "df_train = pd.concat([df_train, df_sex], axis=1)\n",
    "\n",
    "df_sex = pd.get_dummies(df_test['month'])\n",
    "df_test = pd.concat([df_test, df_sex], axis=1)\n",
    "\n",
    "df_sex = pd.get_dummies(df_train['month'])\n",
    "df_train = pd.concat([df_train, df_sex], axis=1)\n",
    "\n",
    "df_sex = pd.get_dummies(df_test['marital'])\n",
    "df_test = pd.concat([df_test, df_sex], axis=1)\n",
    "\n",
    "df_sex = pd.get_dummies(df_train['marital'])\n",
    "df_train = pd.concat([df_train, df_sex], axis=1)  \n",
    "    \n",
    "df_sex = pd.get_dummies(df_test['loan'] )\n",
    "df_test = pd.concat([df_test, df_sex], axis=1)\n",
    "\n",
    "df_sex = pd.get_dummies(df_train['loan'])\n",
    "df_train = pd.concat([df_train, df_sex], axis=1)\n",
    "\n",
    "df_sex = pd.get_dummies(df_test['housing'])\n",
    "df_test = pd.concat([df_test, df_sex], axis=1)\n",
    "\n",
    "df_sex = pd.get_dummies(df_train['housing'])\n",
    "df_train = pd.concat([df_train, df_sex], axis=1)\n",
    "\n",
    "df_sex = pd.get_dummies(df_test['contact'])\n",
    "df_test = pd.concat([df_test, df_sex], axis=1)\n",
    "\n",
    "df_sex = pd.get_dummies(df_train['contact'])\n",
    "df_train = pd.concat([df_train, df_sex], axis=1)\n",
    "\n",
    "df_sex = pd.get_dummies(df_test['poutcome'])\n",
    "df_test = pd.concat([df_test, df_sex], axis=1)\n",
    "\n",
    "df_sex = pd.get_dummies(df_train['poutcome'])\n",
    "df_train = pd.concat([df_train, df_sex], axis=1)\n",
    "\n",
    "\"\"\"df_sex = pd.get_dummies(df_test['day_of_week'])\n",
    "df_test = pd.concat([df_test, df_sex], axis=1)\n",
    "\n",
    "df_sex = pd.get_dummies(df_train['day_of_week'])\n",
    "df_train = pd.concat([df_train, df_sex], axis=1)\"\"\"\n",
    "\n",
    "\"\"\"df_sex = pd.get_dummies(df_test['previous'])\n",
    "df_test = pd.concat([df_test, df_sex], axis=1)\n",
    "\n",
    "df_sex = pd.get_dummies(df_train['previous'])\n",
    "df_train = pd.concat([df_train, df_sex], axis=1)\"\"\"\n",
    "\n",
    "\"\"\"df_sex = pd.get_dummies(df_test['pdays'])\n",
    "df_test = pd.concat([df_test, df_sex], axis=1)\n",
    "\n",
    "df_sex = pd.get_dummies(df_train['pdays'])\n",
    "df_train = pd.concat([df_train, df_sex], axis=1)\"\"\"\n",
    "\n",
    "#scale some data\n",
    "columns_to_standardize =['emp.var.rate', \"duration\",  'cons.price.idx', 'cons.conf.idx', 'euribor3m', \"nr.employed\"]\n",
    "standardize.fit(df_train[columns_to_standardize])\n",
    "\n",
    "df_train[columns_to_standardize] = standardize.transform(df_train[columns_to_standardize])\n",
    "df_test[columns_to_standardize] = standardize.transform(df_test[columns_to_standardize])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#drop_elements = [\"age\", \"job\", \"marital\", \"education\",\"default\",\"housing\",\"loan\",\"contact\",\"month\",\"day_of_week\",\"campaign\",\"pdays\",\"poutcome\",\"emp.var.rate\",\"cons.price.idx\",\"cons.conf.idx\",\"euribor3m\",\"nr.employed\"]\n",
    "\n",
    "#drop_elements = [\"campaign\",\"job\", \"marital\", \"education\", \"default\",\"housing\",\"loan\",\"contact\",\"month\",\"day_of_week\",\"poutcome\",\"nr.employed\",'pdays']\n",
    "\n",
    "drop_elements = ['campaign',\"pdays\",\"poutcome\",\"housing\",\"loan\",\"marital\",\"month\",\"previous\",\"job\", \"education\", \"default\",\"contact\",\"day_of_week\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#from sklearn.model_selection import train_test_split\n",
    "#train, test = train_test_split(df_train, test_size=0.3, random_state=4)\n",
    "\n",
    "#print (train.shape)\n",
    "#print (test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train = df_train.drop(drop_elements, axis = 1)\n",
    "test = df_test.drop(drop_elements, axis = 1)\n",
    "#train  = train.drop(drop_elements, axis = 1)\n",
    "#test  = test.drop(drop_elements, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = list(train.y.values)\n",
    "real = list(test.y.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = train.drop('y', axis = 1)\n",
    "test = test.drop('y', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['age' 'duration' 'emp.var.rate' 'cons.price.idx' 'cons.conf.idx'\n",
      " 'euribor3m' 'nr.employed' 'high' 'low' 'medium' 'apr' 'aug' 'dec' 'jul'\n",
      " 'jun' 'mar' 'may' 'nov' 'oct' 'sep' 'divorced' 'married' 'single' 'loanNo'\n",
      " 'loanYes' 'housingNo' 'housingYes' 'cellular' 'telephone' 'poutfail'\n",
      " 'poutuccess']\n"
     ]
    }
   ],
   "source": [
    "print(train.columns.values)\n",
    "#print(test.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 0.56203148425787108, 1: 4.5302114803625377}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import class_weight\n",
    "class_weight = class_weight.compute_class_weight('balanced', np.unique(y), y)\n",
    "class_weight_dict = dict(enumerate(class_weight))\n",
    "print(class_weight_dict)\n",
    "scale_pos_weight = class_weight_dict[1] / class_weight_dict[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn import svm\n",
    "#clf = svm.SVC(class_weight=class_weight_dict,random_state=22)\n",
    "#clf.fit(train, y) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(min_samples_leaf=10, max_features=0.5, class_weight=class_weight_dict, n_estimators=15, criterion='entropy', random_state=22)\n",
    "clf.fit(train, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mert/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "#import xgboost as xgb\n",
    "#clf = xgb.XGBClassifier(scale_pos_weight=scale_pos_weight,seed=22)\n",
    "#clf.fit(train, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "901 219\n"
     ]
    }
   ],
   "source": [
    "#print(clf.feature_importances_)\n",
    "predictions = clf.predict(test)\n",
    "\n",
    "onecount = 0\n",
    "zeroount = 0\n",
    "\n",
    "for a in predictions:\n",
    "    \n",
    "    if a == 0:\n",
    "        zeroount += 1\n",
    "    else:\n",
    "        onecount += 1\n",
    "print (zeroount,onecount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 0.59703308539419842 on training\n",
    "# 867 253     0.546    clf = xgb.XGBClassifier(scale_pos_weight=scale_pos_weight)\n",
    "\n",
    "# 0.61815990076461025 on training\n",
    "# 886 234    0.52568  clf = RandomForestClassifier(oob_score=True,min_samples_leaf=15, max_features='sqrt', class_weight=class_weight_dict, n_estimators=27, criterion='entropy', random_state=4)\n",
    "\n",
    "# 0.61390917890839247 on traning\n",
    "# 881 239 0.58441     clf = xgb.XGBClassifier(learning_rate=0.11,max_depth=3,subsample=0.9,n_estimators=111, scale_pos_weight=scale_pos_weight,seed=22)\n",
    "\n",
    "# 0.60836537969715088 on traning\n",
    "# 904 216 0.52 clf = RandomForestClassifier(min_samples_leaf=10, max_features=0.5, class_weight=class_weight_dict, n_estimators=15, criterion='gini', random_state=22)\n",
    "\n",
    "# 0.60836537969715088 on traning\n",
    "# 892 228 0.57183 clf = RandomForestClassifier(min_samples_leaf=10, max_features=0.5, class_weight=class_weight_dict, n_estimators=15, criterion='gini', random_state=22)\n",
    "\n",
    "# 0.62203264486456189 on tranining\n",
    "# 893 227  0.54546 clf = RandomForestClassifier(min_samples_leaf=10, max_features=0.5, class_weight=class_weight_dict, n_estimators=15, criterion='gini', random_state=22)\n",
    "\n",
    "# 0.58618062767720858 on traning\n",
    "# 901 219  0.54546 clf = RandomForestClassifier(min_samples_leaf=10, max_features=0.5, class_weight=class_weight_dict, n_estimators=15, criterion='entropy', random_state=22)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.58618062767720858"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import matthews_corrcoef\n",
    "matthews_corrcoef(real, predictions) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output_file = 'Ozer_Mert_Submission.csv'\n",
    "StackingSubmission = pd.DataFrame({ 'prediction': predictions })\n",
    "StackingSubmission.index += 1 \n",
    "StackingSubmission.to_csv(output_file, index=True, index_label='Id')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
